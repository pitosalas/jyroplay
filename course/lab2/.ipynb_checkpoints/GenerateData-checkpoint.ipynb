{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS81 Adaptive Robotics\n",
    "## Lab 2b: Generate neural network training data\n",
    "### Due next Monday before noon\n",
    "---\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this notebook you will generate data for training a neural network to control the robot to find light. You will use your find light brain from the previous lab as the starting point. You will begin as we did before, by defining functions to make the same world and the same robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jyro.simulator import *\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_world(physics):\n",
    "    physics.addBox(0, 0, 4, 4, fill=\"backgroundgreen\", wallcolor=\"gray\")\n",
    "    physics.addBox(1.75, 2.9, 2.25, 3.0, fill=\"blue\", wallcolor=\"blue\")\n",
    "    physics.addLight(2, 3.5, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_robot():\n",
    "    robot = Pioneer(\"Pioneer\", 2, 1, 0)\n",
    "    robot.addDevice(Pioneer16Sonars())\n",
    "    light_sensors = PioneerFrontLightSensors(3) #parameter defines max range\n",
    "    robot.addDevice(light_sensors)\n",
    "    return robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating unique random starting locations\n",
    "\n",
    "In order to generate a robust training set, we'd like to have the robot start from lots of different locations in the world.  Complete the function **random_start(robot)** below by replacing the **pass** line with your solution. We want to ensure that the robot is not placed too close to any walls or too close to the light, therefore choose a random starting location where **x** is between 0.5 and 3.5, **y** is between 0.5 and 2.5, and **heading** is between 0 and 2pi.  Remember that you can use the robot's **setPose(x, y, heading)** method to position the robot at a particular location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_start(robot):\n",
    "   pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test *random_start* function\n",
    "\n",
    "We can create the robot and the visual simulator, and then try calling this function multiple times to see where the robot ends up.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c8edd016984aa48df856c2f06a3708"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "robot = make_robot()\n",
    "vsim = VSimulator(robot, make_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for i in range(10):\n",
    "    random_start(robot)\n",
    "    vsim.update_gui()\n",
    "    sleep(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating translation and rotation amounts\n",
    "\n",
    "In the previous lab you created a *brain* that didn't return anything, but directly controlled the robot by calling **robot.move(translate, rotate)**.  Now we want to both move the robot *and* save the movements to a file. To do this we'll create a function called **determine_move** (based on your finding light brain) that takes in the current sensor values and returns a tuple representing the appropriate translation, rotation amounts for that situation. \n",
    "\n",
    "Be sure that your function stops the robot (using translation of 0 and rotation of 0), when it has reached the light. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_move(lights, sonars):\n",
    "    \"\"\"Returns tuple of (translation, rotation) movement\"\"\"\n",
    "    return (0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test *determine_move* function\n",
    "\n",
    "We can create a brain based on the function above and test that it still properly controls the robot to find the light. Remember to press the *Play* button on the visual simulator above to see the brain at work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_light_brain(robot):\n",
    "    lights = robot[\"light\"].getData()\n",
    "    sonars = robot[\"sonar\"].getData()\n",
    "    translate, rotate = determine_move(lights, sonars)\n",
    "    robot.move(translate, rotate)\n",
    "\n",
    "robot.brain = find_light_brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a file with sensor data and movement commands\n",
    "\n",
    "Now we have all of the pieces in place to generate the training data. \n",
    "\n",
    "We want to generate a lot of data, and the visual simulator will be too slow.  So instead we will use the non-visual version of the simulator. This simulator will only update when explicitly told to step. \n",
    "\n",
    "A key point when creating data for neural network training, is that all of the data should be normalized to fit the range of whatever activation function you plan to use.  We will be using an activation function with a range of [-1,1], because the motor commands can be negative or positive.  The light sensor values are already in the range [0,1] so will not need to be adjusted.  However, the sonar sensor values are in the range [0,5].  So we will normalize these before saving them to the file.  Recall that sonars measure the distance to an obstacle.  The robot doesn't really need to worry about distant obstacles, so let's focus on obstacles within a distance of 3.0.  Any **distance >= 3.0**, normalize to **1.0**.  Any **distance < 3.0**, normalize as **distance/3.0**.\n",
    "\n",
    "Each line of the file we create will consist of sensor values, separated by whitespace, followed by motor commands separated by white space, ending with a newline.\n",
    "\n",
    "One problem we may potentially need to address is that our light finding program may actually get stuck in certain situations, dithering, and never making progress to the light.  We should build our data generating function with this in mind. To do this, determine how many steps your light finding brain typically takes to reach the light.  Increase this by 10-20 percent and designate this as the **max_trial_length**.  For any trial that takes longer than that, we will assume that the robot is stuck and restart at a new random location.\n",
    "\n",
    "Below is the pseudocode for the function you need to write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(robot, make_world, trials, filename):\n",
    "    sim = Simulator(robot, make_world) # create the non-visual simulator\n",
    "    # open a file to write to\n",
    "    for i in range(trials):\n",
    "        # start the robot at a random spot\n",
    "        # display the current trial counter and the robot's starting position\n",
    "        saved_steps = [] # a list to save each step of data associated with an individual trial\n",
    "        while True:\n",
    "            # determine the robot's move using the current light and sonar data\n",
    "            # move the robot\n",
    "            sim.step() # execute one step in the non-visual simulator\n",
    "            # if the robot is stopped this indicates the light was found\n",
    "                 # write each line of the saved_steps list to the file\n",
    "                 # break from the while loop\n",
    "            # if len(saved_steps) > max_trial_length this indicates the robot is likely stuck\n",
    "                 # display that the trial is restarting\n",
    "                 # start the robot at a new random spot\n",
    "                 # reset the saved_steps list to empty\n",
    "            # write the light values to a string\n",
    "            # write the normalized sonar values (only the ones you used) to the same string\n",
    "            # write the translation and rotation amounts to the same string with a newline\n",
    "            # append the string to the saved_steps list       \n",
    "    # close the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test *generate_data* function\n",
    "\n",
    "Call your function to generate 10 trials of data.  Go to a terminal window and look at the file you created. Make sure that each line represents one set of sensor readings and one movement.  Make sure that the light readings are increasing until they eventually peak, and then a new trial starts.  Use the unix command **wc** to see how many lines are in your file (the first number returned).  Calculate the average number of steps your find light strategy needs to reach the light.  As a point of reference, mine takes about 190 steps per trial.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_data(robot, make_world, 10, \"training_data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are sure your data generation function is working properly, use it to generate a large collection of  trials (at least 500)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying the World and the Task\n",
    "\n",
    "NOTE: Completing this section is optional.\n",
    "\n",
    "You may find in doing the next section of this lab that your neural network is not doing very well at finding the light.  One option, is to simplify the original world that we were using by removing the little blue wall in front of the light.  We can also simplify the task by having the **random_start** function choose a smaller range of possible starting headings to ones that are facing more towards the light (where 3pi/4 < heading < 2pi or 0 < heading < pi/4).  Finally we can simplify the controller since, the robot will not be as likely to encounter obstacles.  For example, this simpler controller could be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_move(robot):\n",
    "    lights = robot[\"light\"].getData()\n",
    "    sonars = robot[\"sonar\"].getData()\n",
    "    left_light = lights[0]\n",
    "    right_light = lights[1]\n",
    "    light_diff = abs(left_light-right_light)\n",
    "    if sum(lights) > 1.6:\n",
    "        return (0, 0)\n",
    "    elif min(sonars[2:6]) < 0.3:\n",
    "        return (0, 0.3)\n",
    "    elif light_diff > 0.05:\n",
    "        if right_light > left_light:\n",
    "            return (0, -0.3)\n",
    "        else:\n",
    "            return (0, 0.3)\n",
    "    else:\n",
    "        return (0.3, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like, try generating a new data set using the simplified world and task. See if your neural network is more successful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Use git to add, commit, and push \n",
    "\n",
    "Save this notebook to the repo before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
